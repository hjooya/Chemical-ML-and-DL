## Prediction of Masked SMILES Tokens Using BERT   



<p align="center">
  <img src="https://github.com/hjooya/Chemical-ML-and-DL/blob/main/Transformer_BERT_Masked_SMILES_Prediction/Highlighted_Molecule.jpg" />
</p>

This example shows how to predict masked [SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) tokens using a pretrained [BERT](https://huggingface.co/transformers/v3.0.2/index.html) model. BERT models are trained to perform various tasks. One of the tasks is known as masked language modeling which is the task of predicting token in text that have been replaced by a mask value. This example shows how to predict masked tokens for a given SMILES molecule and calculate the token probabilities using a pretrained BERT model. The image above shows the masked area of the molecule to be predicted.


### Usage

Simply run the MATLAB Live Script "SMILES_BERT.mlx".

### Reference

[Transformers: State-of-the-Art Natural Language Processing](https://aclanthology.org/2020.emnlp-demos.6/)


